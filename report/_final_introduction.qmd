As FinlyWealth expands its offerings from personal finance into the e-commerce sector, it faces the challenge of delivering a scalable and effective product search experience across a rapidly growing and diverse catalog. To address this, a team of Master of Data Science students at the University of British Columbia is developing a machine learning-powered multimodal search engine that understands the semantic meaning of user queries, handling both text and image inputs to help users find relevant products more intuitively and efficiently.  

Search in the e-commerce domain presents unique challenges due to the wide variety of ways users express their search intent. Traditional approaches, such as TF-IDF-based text search, work well for simple queries like “iPhone” or “laptop.” However, most user queries are free-form, complex, and infrequent. The existing system relies on basic keyword matching, lacking semantic understanding, support for multimodal inputs, and large-scale performance evaluation.

### Objective

To address these gaps, this project designed and implemented a fast, scalable multimodal search system that captures semantic meaning of user queries and returns the most relevant products to the users. Architecture components include:

- **Preprocess Script**:  Python scripts runnable via make commands to generate text and image embeddings from raw CSV and image data, and to build FAISS indexes

- **Frontend**: Streamlit for handling interactive text and image queries, and displaying search results along with summary statistics and response time [@streamlit]

- **Backend API**: Flask for query handling and results retrieving [@flask]

      - **Similarity Engine**: FAISS for approximate nearest neighbor search [@faiss]

      - **Post Retrieval Reranking**: GPT-3.5-turbo LLM for reranking the top 30 retrieved candidates based on semantic relevance [@​​openai2023gpt35]

- **Vector Store**: Google Cloud PostgreSQL for affordable and scalable storage of embeddings and metadata

The final data product is evaluated using the following success metrics:  

- Recall@20 for retrieval accuracy
- Latency for query responsiveness (target: under 5 seconds)
- Precision@20 based on manual relevance assessments for qualitative validation
