#### Data Source and Description

The dataset comprises two primary sources: product images and metadata. The image folder contains approximately 15 million, 100x100 pixel JPEG images. It is assumed each product will have a single corresponding image. The metadata file contains 30 columns covering product attributes such as product id, name, description, color, brand and price. FinlyWealth has obtained the dataset from their affiliate network. 

**Missing Values**

Certain columns have missing values in more than 90% of the data, such as “ShortDescription” and “Keywords”. These are unlikely to be used for our data pipeline. 
Other fields such as “Gender”, “Color”, and “Brand” also have a significant proportion of missing values. These are expected since these attributes do not apply to some products such as books. 

**High Cardinality**

Columns such as “Category”, “Color”, “Size”, and “Brand” have high cardinality as shown in @fig-uniquecounts. In addition, columns "Brand" and "Manufacturer" have a 82% overlap in their unique values so the two columns have been merged into "MergedBrand" to eliminate duplication. 

![Unique Counts per Column Diagram](../img/uniquecounts.png){#fig-uniquecounts}

**Overlap Between Product Name and Metadata**

To better understand what users are likely to search for, we analyzed the top 50 most frequent words in product names as shown in @fig-topwords. Common terms like "womens", "mens", "size", and "black" appear frequently and often overlap with metadata fields such as gender and color.

![Top 50 words in product name Diagram](../img/topwords.png){#fig-topwords}

### Methodology: Capturing User Intent

![Workflow Diagram](../img/workflow.png)
{#fig-workflow}

Figure @fig-workflow illustrates the end-to-end architecture, which includes a user interface, an API server for handling queries and doing computations, and a database for storing embeddings and product metadata. The system is designed to retrieve the most relevant products in response to user queries. The workflow is divided into the User-Interface, Server-Side, Database

#### System Workflow

**User Interface:** Users interact with the system through a web interface, where they can input text or image queries to search for products.  The UI is designed for intuitive interaction, allowing users to easily phrase their search intent.

**API Endpoint & Preprocessing:** As seen in the @fig-workflow, when a user enters a query, the query is sent to our API server. For the current implementation we are using Flask[@flask] which is a lightweight webframework. Here, the raw query undergoes several preprocessing steps to ensure compatibility with our retrieval models.

**Embedding Generation**
After the preprocessing, The text is transformed to a format can be easily be used to carry out comparism to data stored in the database. This can either be some form of embedding generation using OpenAi CLIP[@li2021supervision] (Contrastive Language-Image Pre-training) embeddings or using the TF-IDF[@aizawa2003information] (Term Frequency–Inverse Document Frequency) model to create a text representation.

> **Embedding Generation:** The preprocessed query is then transformed into a numerical representation (an embedding) that captures its semantic meaning.

> **TF-IDF:** A numerical statistic used to evaluate the importance of a word in a document within a collection of documents

> **CLIP:** Generates embeddings for both text and images, mapping them into a shared embedding space. We are not training any embedding model, instead we use off-the-shelf [CLIP models](https://huggingface.co/docs/transformers/en/model_doc/clip) to generate embeddings.

**Similarity Calculation & Retrieval:** Once the query and product descriptions are represented as embeddings, we calculate the similarity between them to identify the most relevant products.

We plan to experiment on different similiarity measures which includes cosine similarity[@xia2015learning], euclidean distance, dot product [@ogita2005accurate] etc. This metric provides a score indicating how closely the query and product representations align.
FAISS[@faiss] would also be used to support fast, scalable similiarity calv=culation and retrieval from the Database

> **FAISS** (Facebook AI Similarity Search) is a library that allows developers to quickly search for embeddings of multimedia documents.Enables efficient approximate nearest neighbor search over embeddings.

**Hybrid Retrieval:** We combine results from CLIP and TF-IDF using a weighted scoring system:

- Each model returns a relevance score for a user query.
- Scores are weighted (e.g., 70% CLIP, 30% TF-IDF) and merged.
- The final ranked list balances semantic relevance with textual precision.

This hybrid approach improves retrieval accuracy across varied query types and product data quality.

What is this embeddings compared against? In out implementation, we stored an embedding representation of all product items.

**Database & Indexing:** To enable efficient retrieval of relevant products, we store the preprocessed product information, combining several metadata to generate the corresponding embeddings in a centralized database alongside their product metadata (e.g., title, description, price, brand). We would be doing extensive research of the optimized Database. Such examples include, Pinecone[@pinecone], ChromaDB[@chromadb], PostgresSQL[@postgresql] etc

Fast and efficient similarity search over large collections of high-dimensional vectors, which is crucial for the performance of our semantic search system. For TF-IDF, an inverted index is used to enable efficient retrieval of documents containing specific terms.

**Baseline Approach: TF-IDF:**We will implement a TF-IDF-based retrieval model as a baseline. TF-IDF is a well-established, interpretable, and lightweight method that ranks documents by the importance of query terms, making it effective in structured domains like e-commerce for keyword matching. While it doesn't capture semantic meaning like CLIP, it serves as a strong, interpretable baseline for assessing retrieval performance.


**Tools and Libraries:**A variety of tools and libraries are used in this project to support data processing, model serving, image handling, and vector search. These tools include Numpy[@harris2020array] for array calculation, Flask[@flask] for web development, Pillow[@pillow] for handling image input from users, Spacy[@spacy] for natural language processing, Huggingface[@huggingface] for using models other developers have open-sourced etc. 

#### Implementation Challenges

We anticipate several challenges in implementing this system at scale. Scalability concerns, such as latency and memory, will need to be addressed to ensure efficient retrieval from a large product catalog. Data quality issues, including hig cardinality in metadata columns, may impact the accuracy of both TF-IDF and CLIP-based retrieval. Evaluating the performance of multimodal queries presents a further challenge, as it requires defining appropriate metrics to measure the "goodness" of retrieval. Additionally, determining the optimal weights for combining semantic and lexical scores in our hybrid retrieval approach will require careful tuning and experimentation.