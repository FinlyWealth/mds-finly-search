#### Data Source and Description

The dataset consists of multi-modal product data, including images, textual descriptions, and structured metadata. It includes:

- 14,684,588 JPEG images (approximately 67 GB), each under 150×150 pixels. Image filenames correspond to the Pid field in the metadata CSV. Although the number of images is slightly lower than the number of unique product entries (15,147,805), it's possible that some products have multiple images while others have none. However, our project partner confirmed that we will assume a 1:1 mapping between images and product listings based on Pid.

- A 12 GB CSV file containing 15,384,100 rows and 30 columns, with each row representing a product listing. The metadata includes attributes such as Pid, Name, Description, Category, Brand, Color, Price, Gender, and product URLs.

The dataset was provided by FinlyWealth through its affiliate network and will serve as the foundation for both exploratory analysis and model development.

#### Exploratory Data Analysis

Several metadata columns contain substantial missing values and were therefore dropped in favor of more complete fields (see @tbl-dropcolumns). Attributes like Color, Gender, and Brand also have missing data but are retained, as they still offer value for modeling (see @tbl-keptcolumns). The missingness in these fields may be due to certain product types—such as books—not supporting these attributes (see the category distribution in @fig-categorydist). 

: Table: Summary of Rropped columns and Reasons {#tbl-dropcolumns}

| **Attribute**         | **Reason Dropped**                               |
|-----------------------|--------------------------------------------------|
| `ShortDescription`    | 91% missing                                      |
| `Keywords`            | 99% missing                                      |
| `CategoryId`          | Redundant with `Category`                        |
| `ImageURL`            | Not used directly in modeling                    |
| `SalePrice`           | Redundant with `FinalPrice` / incomplete usage   |
| `PriceCurrency`       | Not used in current modeling scope               |
| `MPN`                 | High cardinality (~2.3M values), sparse          |
| `UPCorEAN`            | High cardinality (~3.5M values), sparse          |
| `SKU`                 | Redundant with `Pid` (~10M values)               |
| `AlternateImageUrl*`  | Not used, only primary image needed              |
| `DeepLinkURL`         | Not relevant for modeling                        |
| `LinkUrl`             | Not relevant for modeling                        |

: Table: Summary of Retained Columns and Their Characteristics {#tbl-keptcolumns}

| **Group**              | **Attribute**     | **Description / Examples**                               |
|------------------------|-------------------|----------------------------------------------------------|
| Identifiers            | `Pid`             | Unique product ID; links to image filenames              |
| Text Fields            | `Name`            | Product title (0.2% missing)                             |
|                        | `Description`     | Product description (0.03% missing)                      |
|                        | `Category`        | Product category (28% missing, ~15K values)              |
| Pricing & Availability | `Price`           | Listed price                                             |
|                        | `FinalPrice`      | Final price after discounts                              |
|                        | `Discount`        | Discount percentage or value                             |
|                        | `isOnSale`        | Boolean flag (2 values)                                  |
|                        | `IsInStock`       | Boolean flag (2 values)                                  |
| Branding               | `Brand`           | Brand name (53% missing, ~21K unique)                    |
|                        | `Manufacturer`    | Manufacturer name (34% missing, ~26K unique)             |
| Product Features       | `Color`           | Product color (49% missing, ~170K unique)                |
|                        | `Gender`          | Target gender (54% missing, 3 values: e.g., male/female) |
|                        | `Size`            | Product size (46% missing, ~55K unique)                  |
|                        | `Condition`       | Product condition (e.g., new, used; 5 values)            |

![Top 8 Product Categories with Others Grouped](../img/categorydist.png){#fig-categorydist}

High-cardinality fields such as Category, Size, and Brand (see @fig-uniquecounts) may require grouping rare values to avoid overfitting and reduce memory usage. We merged Brand and Manufacturer into a single MergedBrand column to reduce duplication while preserving distinct information from both fields. We also excluded non-English market entries, keeping approximately 70% of the dataset, as confirmed by the partner. 

![Unique Value Counts per Column After Data Cleaning](../img/uniquecounts.png){#fig-uniquecounts}

To better understand what users are likely to search for, we analyzed the 50 most frequent words in product names, as shown in @fig-topwords. Common terms like "womens", "mens", "size", and "black" appear frequently and often overlap with metadata fields such as gender and color.

![Top 50 words in product name Diagram](../img/topwords.png){#fig-topwords}

### Methodology: Capturing User Intent

![Workflow Diagram](../img/workflow.png){#fig-workflow}

Figure @fig-workflow illustrates the end-to-end architecture, which includes a user interface, an API server for handling queries and doing computations, and a database for storing embeddings and product metadata. The system is designed to retrieve the most relevant products in response to user queries. The workflow is divided into the User-Interface, Server-Side, Database

#### System Workflow

**User Interface:** Users interact with the system through a web interface, where they can input text or image queries to search for products.  The UI is designed for intuitive interaction, allowing users to easily phrase their search intent.

**API Endpoint & Preprocessing:** As seen in the @fig-workflow, when a user enters a query, the query is sent to our API server. For the current implementation we are using Flask[@flask] which is a lightweight webframework. Here, the raw query undergoes several preprocessing steps to ensure compatibility with our retrieval models.

**Embedding Generation**
After the preprocessing, The text is transformed to a format can be easily be used to carry out comparism to data stored in the database. This can either be some form of embedding generation using OpenAi CLIP[@openaiclip] (Contrastive Language-Image Pre-training) embeddings or using the TF-IDF[@aizawa2003information] (Term Frequency–Inverse Document Frequency) model to create a text representation.

> **Embedding Generation:** The preprocessed query is then transformed into a numerical representation (an embedding) that captures its semantic meaning.

> **TF-IDF:** A numerical statistic used to evaluate the importance of a word in a document within a collection of documents

> **CLIP:** Generates embeddings for both text and images, mapping them into a shared embedding space. We are not training any embedding model, instead we use off-the-shelf [CLIP models](https://huggingface.co/docs/transformers/en/model_doc/clip) to generate embeddings.

**Similarity Calculation & Retrieval:** Once the query and product descriptions are represented as embeddings, we calculate the similarity between them to identify the most relevant products.

We plan to experiment on different similiarity measures which includes cosine similarity[@xia2015learning], euclidean distance, dot product [@ogita2005accurate] etc. This metric provides a score indicating how closely the query and product representations align.
FAISS[@faiss] would also be used to support fast, scalable similiarity calv=culation and retrieval from the Database

> **FAISS** (Facebook AI Similarity Search) is a library that allows developers to quickly search for embeddings of multimedia documents.Enables efficient approximate nearest neighbor search over embeddings.

**Hybrid Retrieval:** We combine results from CLIP and TF-IDF using a weighted scoring system:

- Each model returns a relevance score for a user query.
- Scores are weighted (e.g., 70% CLIP, 30% TF-IDF) and merged.
- The final ranked list balances semantic relevance with textual precision.

This hybrid approach improves retrieval accuracy across varied query types and product data quality.

What is this embeddings compared against? In out implementation, we stored an embedding representation of all product items.

**Database & Indexing:** To enable efficient retrieval of relevant products, we store the preprocessed product information, combining several metadata to generate the corresponding embeddings in a centralized database alongside their product metadata (e.g., title, description, price, brand). We would be doing extensive research of the optimized Database. Such examples include, Pinecone[@pinecone], ChromaDB[@chromadb], PostgresSQL[@postgresql] etc

Fast and efficient similarity search over large collections of high-dimensional vectors, which is crucial for the performance of our semantic search system. For TF-IDF, an inverted index is used to enable efficient retrieval of documents containing specific terms.

**Baseline Approach: TF-IDF:**We will implement a TF-IDF-based retrieval model as a baseline. TF-IDF is a well-established, interpretable, and lightweight method that ranks documents by the importance of query terms, making it effective in structured domains like e-commerce for keyword matching. While it doesn't capture semantic meaning like CLIP, it serves as a strong, interpretable baseline for assessing retrieval performance.


**Tools and Libraries:**A variety of tools and libraries are used in this project to support data processing, model serving, image handling, and vector search. These tools include Numpy[@harris2020array] for array calculation, Flask[@flask] for web development, Pillow[@pillow] for handling image input from users, Spacy[@spacy] for natural language processing, Huggingface[@huggingface] for using models other developers have open-sourced etc. 

#### Implementation Challenges

We anticipate several challenges in implementing this system at scale. Scalability concerns, such as latency and memory, will need to be addressed to ensure efficient retrieval from a large product catalog. Data quality issues, including hig cardinality in metadata columns, may impact the accuracy of both TF-IDF and CLIP-based retrieval. Evaluating the performance of multimodal queries presents a further challenge, as it requires defining appropriate metrics to measure the "goodness" of retrieval. Additionally, determining the optimal weights for combining semantic and lexical scores in our hybrid retrieval approach will require careful tuning and experimentation.