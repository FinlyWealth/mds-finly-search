#### Data Source, Description and Cleaning          

The dataset consists of multimodal product data, including images (14,684,588 JPEG files, approximately 67 GB), textual information (product names and descriptions), and structured metadata (e.g., `Category`, `Brand`, `Color`). The metadata is stored in a 12 GB CSV file containing 15,384,100 rows and 30 columns.

After conducting exploratory data analysis and consulting with our partner, we selected the 16 most relevant columns that capture the key information users care about. We excluded non-English market entries—retaining approximately 70% of the dataset—in line with our partner’s business focus. Additionally, we merged the `Brand` and `Manufacturer` columns into a single `MergedBrand` field to reduce duplication while preserving distinct brand information. We chose to ignore missing values in the metadata columns, as these fields are likely to provide supplementary information, while the product name already contains the primary details.

: Table: Summary of Retained Columns and Their Characteristics {#tbl-keptcolumns}

| **Group**               | **Attribute**    | **Description / Examples**                               |
|-------------------------|------------------|----------------------------------------------------------|
| **Identifiers**         | `Pid`            | Unique product ID; links to image filenames              |
| **Text Fields**         | `Name`           | Product title (0.2% missing)                             |
|                         | `Description`    | Product description (0.03% missing)                      |
|                         | `Category`       | Product category (28% missing; ~15 K unique values)      |
| **Pricing & Availability** | `Price`       | Listed price                                            |
|                         | `"PriceCurrency"`   | Currency of the price                              |
|                         | `FinalPrice`     | Final price after discounts                              |
|                         | `Discount`       | Discount percentage or value                             |
|                         | `isOnSale`       | Boolean flag                                            |
|                         | `IsInStock`      | Boolean flag                                            |
| **Branding**            | `Brand`          | Brand name (53% missing; ~21 K unique values)            |
|                         | `Manufacturer`   | Manufacturer name (34% missing; ~26 K unique values)     |
| **Product Features**    | `Color`          | Product color (49% missing; ~170 K unique values)        |
|                         | `Gender`         | Target gender (54% missing; 3 values: e.g., male/female) |
|                         | `Size`           | Product size (46% missing; ~55 K unique values)          |
|                         | `Condition`      | Product condition (e.g., new, used; 5 values)            |

### Data Science Techniques

Our goal was to build a multimodal search engine that returns relevant product results in response to diverse customer queries. To achieve this, we focused on combining text and image understanding with scalable retrieval techniques. We designed a hybrid retrieval system that combines full text search, multimodal embeddings and LLM reranking to improve the relevance of product search results. This pipeline integrates TF-IDF (Term Frequency-Inverse Document Frequency) for full text search, CLIP for image-text understanding, MiniLM for lightweight semantic understanding, FAISS (Facebook AI Similarity Search) for fast retrieval, and OpenAI GPT3.5 LLM (Large Language Model) for reranking.

#### TF-IDF
TF-IDF is a keyword-based search method that ranks products based on how uniquely their descriptions match the search query.

#### CLIP and MiniLM Embedding
We were inspired by [@liu2025multimodal], who combined CLIP and a [@devlin2019bert] model fine-tuned on e-commerce data to improve product search. Since we didn’t have access to labeled domain-specific data for fine-tuning, we chose a smaller, faster transformer model that performs well out-of-the-box that supports semantic understanding.

[@openaiclip] [@huggingfaceMinilm] 

#### FAISS
FAISS  is a library for efficient similarity search and clustering of dense vectors. It enables fast retrieval from large-scale embedding databases using indexing techniques like IVF (Inverted File Indexing). A preprocessing step is required to build this index so it can be searched through when a user submits a query. 

#### Large Language Model
A LLM is used to help improve search quality by re-ranking initial product results based on deeper semantic understanding. It interprets the user’s intent and assesses the relevance of each product based on the following:

1. Semantic similarity to the query intent
2. Direct keyword matches
3. Brand Name mentions
4. Price comparison

### Preprocessing Pipeline

### Search Pipeline
![Workflow for a Search Query](../../img/search-pipeline.png)


### Evaluation