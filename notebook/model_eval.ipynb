{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../src')\n",
    "from preprocess import initialize_clip_model, generate_embedding\n",
    "from retrieval import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device is mps\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.mps.is_available() else \"cpu\"\n",
    "print(f\"Device is {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                                   Pid  \\\n",
       "0   230765.156074.66EA81FE0710E584.26DCA022C55D334...   \n",
       "1   230765.156074.66EA81FE0710E584.26DCA022C55D334...   \n",
       "2   230765.156074.66EA81FE0710E584.26DCA022C55D334...   \n",
       "3   178866.156074.820F1205554371C6.94435B3E5252BCD...   \n",
       "4   178866.156074.820F1205554371C6.94435B3E5252BCD...   \n",
       "5   178866.156074.820F1205554371C6.94435B3E5252BCD...   \n",
       "6   178866.156074.820F1205554371C6.BF3F547DC44EC64...   \n",
       "7   178866.156074.820F1205554371C6.BF3F547DC44EC64...   \n",
       "8   178866.156074.820F1205554371C6.BF3F547DC44EC64...   \n",
       "9   159390.1.5EDD.B3A17A41A080BDA.US-10292524WH-5-...   \n",
       "10  159390.1.5EDD.B3A17A41A080BDA.US-10292524WH-5-...   \n",
       "11  159390.1.5EDD.B3A17A41A080BDA.US-10292524WH-5-...   \n",
       "12  159390.1.5EDD.7568CF40E1FC370A.US-30284883TO-3...   \n",
       "13  159390.1.5EDD.7568CF40E1FC370A.US-30284883TO-3...   \n",
       "14  159390.1.5EDD.7568CF40E1FC370A.US-30284883TO-3...   \n",
       "15  230765.156074.9E8AD04DF5D4FE7B.3BC8878B87A0460...   \n",
       "16  230765.156074.9E8AD04DF5D4FE7B.3BC8878B87A0460...   \n",
       "17  230765.156074.9E8AD04DF5D4FE7B.3BC8878B87A0460...   \n",
       "18  230765.156074.9E8AD04DF5D4FE7B.CFF09BDB285F3A6...   \n",
       "19  230765.156074.9E8AD04DF5D4FE7B.CFF09BDB285F3A6...   \n",
       "20  230765.156074.9E8AD04DF5D4FE7B.CFF09BDB285F3A6...   \n",
       "21  228963.156074.5BD1DE98FA94FFB1.F403820EFB11A4B...   \n",
       "22  228963.156074.5BD1DE98FA94FFB1.F403820EFB11A4B...   \n",
       "23  228963.156074.5BD1DE98FA94FFB1.F403820EFB11A4B...   \n",
       "24  178866.156074.820F1205554371C6.51D5532837F7ABB...   \n",
       "25  178866.156074.820F1205554371C6.51D5532837F7ABB...   \n",
       "26  178866.156074.820F1205554371C6.51D5532837F7ABB...   \n",
       "27  162510.2.8FC07D5199D7103.92298BFDF63CF2B6.SG66...   \n",
       "28  162510.2.8FC07D5199D7103.92298BFDF63CF2B6.SG66...   \n",
       "29  162510.2.8FC07D5199D7103.92298BFDF63CF2B6.SG66...   \n",
       "\n",
       "                                                 Name  \\\n",
       "0                 TEMU 26pcs Silicone Daisy Beads Set   \n",
       "1                 TEMU 26pcs Silicone Daisy Beads Set   \n",
       "2                 TEMU 26pcs Silicone Daisy Beads Set   \n",
       "3   This Annoying Home Life: A Mindless Coloring B...   \n",
       "4   This Annoying Home Life: A Mindless Coloring B...   \n",
       "5   This Annoying Home Life: A Mindless Coloring B...   \n",
       "6                                     A February Face   \n",
       "7                                     A February Face   \n",
       "8                                     A February Face   \n",
       "9     Puma Man T-shirt Black Size M Cotton, Polyester   \n",
       "10    Puma Man T-shirt Black Size M Cotton, Polyester   \n",
       "11    Puma Man T-shirt Black Size M Cotton, Polyester   \n",
       "12  Cos Woman Pants Midnight blue Size 4 Organic c...   \n",
       "13  Cos Woman Pants Midnight blue Size 4 Organic c...   \n",
       "14  Cos Woman Pants Midnight blue Size 4 Organic c...   \n",
       "15          TEMU 20pcs Low Temperature Soldering Rods   \n",
       "16          TEMU 20pcs Low Temperature Soldering Rods   \n",
       "17          TEMU 20pcs Low Temperature Soldering Rods   \n",
       "18  TEMU Elegant Solid Color Women's Dress With In...   \n",
       "19  TEMU Elegant Solid Color Women's Dress With In...   \n",
       "20  TEMU Elegant Solid Color Women's Dress With In...   \n",
       "21  Iowa Hawkeyes Champion Women's Bella T-Shirt S...   \n",
       "22  Iowa Hawkeyes Champion Women's Bella T-Shirt S...   \n",
       "23  Iowa Hawkeyes Champion Women's Bella T-Shirt S...   \n",
       "24  Baking Day!: Ready-to-Read Pre-Level 1 (Daniel...   \n",
       "25  Baking Day!: Ready-to-Read Pre-Level 1 (Daniel...   \n",
       "26  Baking Day!: Ready-to-Read Pre-Level 1 (Daniel...   \n",
       "27  Chlo CH0225SK Asian Fit 002 Women's Sunglasses...   \n",
       "28  Chlo CH0225SK Asian Fit 002 Women's Sunglasses...   \n",
       "29  Chlo CH0225SK Asian Fit 002 Women's Sunglasses...   \n",
       "\n",
       "                                                Query  \n",
       "0                                silicone daisy beads  \n",
       "1   daisy bead making kit for keychains and bracelets  \n",
       "2   TEMU 26pcs silicone daisy crafting beads set f...  \n",
       "3                         annoying life coloring book  \n",
       "4              stress relief coloring book for adults  \n",
       "5   mindless adult coloring book for stress and an...  \n",
       "6                                a february face book  \n",
       "7                        poetic novel A February Face  \n",
       "8   A February Face coming-of-age fiction book wit...  \n",
       "9                                  black puma t-shirt  \n",
       "10             puma men's black cotton t-shirt size M  \n",
       "11  medium size Puma black men’s t-shirt in cotton...  \n",
       "12                            cos midnight blue pants  \n",
       "13   size 4 COS organic cotton blend women's trousers  \n",
       "14  COS women's fitted pants in midnight blue with...  \n",
       "15                               low temp solder rods  \n",
       "16  TEMU metal soldering rods for copper and aluminum  \n",
       "17  non-toxic low temp solder rods for DIY repair ...  \n",
       "18                                   cape shawl dress  \n",
       "19          pleated polyester women's dress with cape  \n",
       "20  elegant solid color women's dress with pleated...  \n",
       "21                                iowa hawkeyes shirt  \n",
       "22      women's champion t-shirt small white hawkeyes  \n",
       "23  small women's white Champion Bella t-shirt Iow...  \n",
       "24                            daniel tiger baking day  \n",
       "25                        baking day pre-level reader  \n",
       "26  Daniel Tiger's Neighborhood early reader Bakin...  \n",
       "27                     chloe tortoiseshell sunglasses  \n",
       "28        CH0225SK chloe women’s sunglasses asian fit  \n",
       "29  Chloe CH0225SK tortoiseshell women’s sunglasse...  >"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('benchmark.csv')\n",
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(CLIPProcessor:\n",
       " - image_processor: CLIPImageProcessor {\n",
       "   \"crop_size\": {\n",
       "     \"height\": 224,\n",
       "     \"width\": 224\n",
       "   },\n",
       "   \"do_center_crop\": true,\n",
       "   \"do_convert_rgb\": true,\n",
       "   \"do_normalize\": true,\n",
       "   \"do_rescale\": true,\n",
       "   \"do_resize\": true,\n",
       "   \"image_mean\": [\n",
       "     0.48145466,\n",
       "     0.4578275,\n",
       "     0.40821073\n",
       "   ],\n",
       "   \"image_processor_type\": \"CLIPImageProcessor\",\n",
       "   \"image_std\": [\n",
       "     0.26862954,\n",
       "     0.26130258,\n",
       "     0.27577711\n",
       "   ],\n",
       "   \"resample\": 3,\n",
       "   \"rescale_factor\": 0.00392156862745098,\n",
       "   \"size\": {\n",
       "     \"shortest_edge\": 224\n",
       "   }\n",
       " }\n",
       " \n",
       " - tokenizer: CLIPTokenizerFast(name_or_path='openai/clip-vit-base-patch32', vocab_size=49408, model_max_length=77, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|startoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|endoftext|>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
       " \t49406: AddedToken(\"<|startoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       " \t49407: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " }\n",
       " )\n",
       " \n",
       " {\n",
       "   \"processor_class\": \"CLIPProcessor\"\n",
       " },\n",
       " CLIPModel(\n",
       "   (text_model): CLIPTextTransformer(\n",
       "     (embeddings): CLIPTextEmbeddings(\n",
       "       (token_embedding): Embedding(49408, 512)\n",
       "       (position_embedding): Embedding(77, 512)\n",
       "     )\n",
       "     (encoder): CLIPEncoder(\n",
       "       (layers): ModuleList(\n",
       "         (0-11): 12 x CLIPEncoderLayer(\n",
       "           (self_attn): CLIPSdpaAttention(\n",
       "             (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "           )\n",
       "           (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "           (mlp): CLIPMLP(\n",
       "             (activation_fn): QuickGELUActivation()\n",
       "             (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "             (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "           )\n",
       "           (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "   )\n",
       "   (vision_model): CLIPVisionTransformer(\n",
       "     (embeddings): CLIPVisionEmbeddings(\n",
       "       (patch_embedding): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)\n",
       "       (position_embedding): Embedding(50, 768)\n",
       "     )\n",
       "     (pre_layrnorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "     (encoder): CLIPEncoder(\n",
       "       (layers): ModuleList(\n",
       "         (0-11): 12 x CLIPEncoderLayer(\n",
       "           (self_attn): CLIPSdpaAttention(\n",
       "             (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "           )\n",
       "           (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "           (mlp): CLIPMLP(\n",
       "             (activation_fn): QuickGELUActivation()\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "           )\n",
       "           (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (post_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "   )\n",
       "   (visual_projection): Linear(in_features=768, out_features=512, bias=False)\n",
       "   (text_projection): Linear(in_features=512, out_features=512, bias=False)\n",
       " ))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Models to test\n",
    "clip_model = \"openai/clip-vit-base-patch32\"\n",
    "initialize_clip_model(clip_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@5: 0.7000\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "hits = 0\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    query_text = row.get('Query', None)\n",
    "\n",
    "    embedding = generate_embedding(query_text=query_text)\n",
    "    \n",
    "    # Run retrieval\n",
    "    retrieved_pids, _ = hybrid_search(query_text, embedding, top_k=k)\n",
    "    \n",
    "    # Check if the ground truth Pid is in the top-k results\n",
    "    if row['Pid'] in retrieved_pids:\n",
    "        hits += 1\n",
    "\n",
    "recall_at_k = hits / len(df)\n",
    "print(f\"Recall@{k}: {recall_at_k:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 175990,
     "sourceId": 396802,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "finly",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
